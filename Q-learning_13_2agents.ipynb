{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 100\n",
    "MAX_STEPS = 200\n",
    "COLUMNS = 10\n",
    "ROWS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(GridEnv, self).__init__()\n",
    "        self.action_space = spaces.Discrete(4) # Up, Down, Left, Right\n",
    "        self.observation_space = spaces.Box(low=np.array([0, 0]), high=np.array([ROWS - 1, COLUMNS - 1]), dtype=np.int32)\n",
    "        self.reward_map = None\n",
    "        self.obstacle_position = [np.random.randint(ROWS), np.random.randint(COLUMNS)]\n",
    "        self.step_counter = 0\n",
    "        self.total_rewards_collected = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state_agent1 = np.array([0, 0])  # Starting position for agent 1\n",
    "        self.state_agent2 = np.array([ROWS - 1, COLUMNS - 1])  # Starting position for agent 2\n",
    "        self.initialize_reward_map()\n",
    "        self.step_counter = 0\n",
    "        self.total_rewards_collected = 0\n",
    "        return self.state_agent1, self.state_agent2\n",
    "    \n",
    "    def initialize_reward_map(self):\n",
    "        self.reward_map = np.full((ROWS, COLUMNS), 1)\n",
    "        self.reward_map[self.obstacle_position[0], self.obstacle_position[1]] = -100\n",
    "        # self.reward_map[self.state[0], self.state[1]] = 100  # Set the starting column to 0\n",
    "        # self.reward_map[ROWS-1,0] = 100\n",
    "        # self.reward_map[-1, :] = 100  # Set the bottom row to 100\n",
    "            \n",
    "    def reset_reward_map(self):\n",
    "        self.initialize_reward_map()\n",
    "        self.reward_map[0,0] = -1  # Mark the starting position\n",
    "\n",
    "\n",
    "    def step(self, action_agent1, action_agent2):\n",
    "        # Apply action for agent 1\n",
    "        new_state_agent1, reward_agent1, done_agent1 = self.apply_action(self.state_agent1, action_agent1)\n",
    "\n",
    "        # Apply action for agent 2\n",
    "        new_state_agent2, reward_agent2, done_agent2 = self.apply_action(self.state_agent2, action_agent2)\n",
    "\n",
    "        # Update states for both agents\n",
    "        self.state_agent1 = new_state_agent1\n",
    "        self.state_agent2 = new_state_agent2\n",
    "\n",
    "        # Update the reward map to reflect movements of both agents\n",
    "        y1, x1 = self.state_agent1\n",
    "        y2, x2 = self.state_agent2\n",
    "        self.reward_map[y1, x1] = -1  # Mark position for agent 1\n",
    "        self.reward_map[y2, x2] = -1  # Mark position for agent 2\n",
    "\n",
    "        # Check if either agent is done\n",
    "        done = done_agent1 or done_agent2\n",
    "\n",
    "        return (new_state_agent1, new_state_agent2), (reward_agent1, reward_agent2), done, {}\n",
    "        \n",
    "    def apply_action(self, state, action):\n",
    "        # Initialize reward and done flag\n",
    "        reward = 0.\n",
    "        done = False\n",
    "\n",
    "        # Action mappings (no changes here)\n",
    "        action_mappings = {\n",
    "            0: (-1, 0),  # Move up\n",
    "            1: (1, 0),   # Move down\n",
    "            2: (0, -1),  # Move left\n",
    "            3: (0, 1)    # Move right\n",
    "        }\n",
    "\n",
    "        # Update state based on action\n",
    "        delta = action_mappings.get(action, (0, 0))\n",
    "        new_state = np.array([state[0] + delta[0], state[1] + delta[1]])\n",
    "\n",
    "        # Check and handle boundary conditions\n",
    "        if new_state[0] < 0 or new_state[0] >= ROWS or new_state[1] < 0 or new_state[1] >= COLUMNS:\n",
    "            reward = -100\n",
    "            done = True\n",
    "        else:\n",
    "            reward = self.calculate_reward(new_state)\n",
    "            done = self.is_done()\n",
    "\n",
    "        return new_state, reward, done\n",
    "    \n",
    "    def calculate_reward(self, state):\n",
    "        # Calculate reward based on the current state\n",
    "        return self.reward_map[state[0], state[1]]\n",
    "\n",
    "    def is_done(self):\n",
    "        # Check if all cells in the grid have been visited or if a step limit is reached\n",
    "        max_steps = MAX_STEPS\n",
    "        return np.all(self.reward_map == -1) or self.step_counter >= max_steps\n",
    "            \n",
    "    def render(self, mode='human'):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(self.reward_map, cmap='viridis', origin='lower')\n",
    "\n",
    "        # Plot Agent 1's position\n",
    "        plt.scatter(self.state_agent1[1], self.state_agent1[0], c='red', marker='o', label='Agent 1')\n",
    "\n",
    "        # Plot Agent 2's position\n",
    "        plt.scatter(self.state_agent2[1], self.state_agent2[0], c='blue', marker='o', label='Agent 2')\n",
    "\n",
    "        plt.title(\"Agents' Movement in Grid\")\n",
    "        plt.legend()\n",
    "        plt.pause(0.1)  # Pause for a short period to create animation effect\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, env, learning_rate=0.2, discount_factor=0.9, epsilon=0.1, gasoline_capacity=1000, wheat_capacity=100):\n",
    "        self.env = env\n",
    "        self.gasoline = gasoline_capacity  # Initial gasoline level\n",
    "        self.wheat = 0  # Initial wheat level\n",
    "        self.gasoline_capacity = gasoline_capacity\n",
    "        self.wheat_capacity = wheat_capacity\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = np.zeros((ROWS, COLUMNS, env.action_space.n))\n",
    "\n",
    "    def choose_action(self, state, neg_reward):\n",
    "        if neg_reward > 3:\n",
    "            # Implement logic to find the nearest positive reward\n",
    "            action = self.find_nearest_positive_reward_action(state)\n",
    "        elif np.random.uniform(0, 1) < self.epsilon:\n",
    "            action = self.env.action_space.sample()  # Explore: random action\n",
    "        else:\n",
    "            state_index = (state[0], state[1])\n",
    "            action = np.argmax(self.q_table[state_index])  # Exploit: best known action\n",
    "        return action    \n",
    "    \n",
    "    def find_nearest_positive_reward_action(self, state):\n",
    "        min_distance = float('inf')\n",
    "        best_action = None\n",
    "\n",
    "        # Search the grid for the nearest positive reward\n",
    "        for y in range(ROWS):\n",
    "            for x in range(COLUMNS):\n",
    "                if self.env.reward_map[y, x] > 0:  # Check for positive reward\n",
    "                    distance = abs(state[0] - y) + abs(state[1] - x)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_action = self.determine_action_to_reward(state, (y, x))\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    def determine_action_to_reward(self, current_state, reward_state):\n",
    "        dy = reward_state[0] - current_state[0]\n",
    "        dx = reward_state[1] - current_state[1]\n",
    "\n",
    "        if abs(dy) > abs(dx):\n",
    "            return 1 if dy > 0 else 0  # Move down (1) or up (0) based on the y-difference\n",
    "        else:\n",
    "            return 3 if dx > 0 else 2  # Move right (3) or left (2) based on the x-difference\n",
    "    \n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        state_index = (state[0], state[1])\n",
    "        next_state_index = (next_state[0], next_state[1])\n",
    "        # Update rule for Q-learning\n",
    "        best_next_action = np.argmax(self.q_table[next_state_index])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state_index][best_next_action]\n",
    "        td_error = td_target - self.q_table[state_index][action]\n",
    "        self.q_table[state_index][action] += self.learning_rate * td_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(env, agent1, agent2, episodes):\n",
    "    best_total_reward_agent1 = -float('inf')\n",
    "    best_total_reward_agent2 = -float('inf')\n",
    "    best_path_agent1 = []\n",
    "    best_path_agent2 = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state_agent1, state_agent2 = env.reset()\n",
    "        current_path_agent1 = [state_agent1]\n",
    "        current_path_agent2 = [state_agent2]\n",
    "        done = False\n",
    "        total_reward_agent1 = 0\n",
    "        total_reward_agent2 = 0\n",
    "        neg_reward_agent1 = 0\n",
    "        neg_reward_agent2 = 0\n",
    "\n",
    "        while not done:\n",
    "            action_agent1 = agent1.choose_action(state_agent1, neg_reward_agent1)\n",
    "            action_agent2 = agent2.choose_action(state_agent2, neg_reward_agent2)\n",
    "\n",
    "            (next_state_agent1, next_state_agent2), (reward_agent1, reward_agent2), done, _ = env.step(action_agent1, action_agent2)\n",
    "\n",
    "            agent1.learn(state_agent1, action_agent1, reward_agent1, next_state_agent1)\n",
    "            agent2.learn(state_agent2, action_agent2, reward_agent2, next_state_agent2)\n",
    "\n",
    "            state_agent1, state_agent2 = next_state_agent1, next_state_agent2\n",
    "            total_reward_agent1 += reward_agent1\n",
    "            total_reward_agent2 += reward_agent2\n",
    "            current_path_agent1.append(state_agent1)\n",
    "            current_path_agent2.append(state_agent2)\n",
    "\n",
    "            if reward_agent1 < 0:\n",
    "                neg_reward_agent1 += 1\n",
    "            else:\n",
    "                neg_reward_agent1 = 0\n",
    "\n",
    "            if reward_agent2 < 0:\n",
    "                neg_reward_agent2 += 1\n",
    "            else:\n",
    "                neg_reward_agent2 = 0\n",
    "\n",
    "        if total_reward_agent1 > best_total_reward_agent1:\n",
    "            best_total_reward_agent1 = total_reward_agent1\n",
    "            best_path_agent1 = current_path_agent1\n",
    "\n",
    "        if total_reward_agent2 > best_total_reward_agent2:\n",
    "            best_total_reward_agent2 = total_reward_agent2\n",
    "            best_path_agent2 = current_path_agent2\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode {episode}: Total Reward Agent 1: {total_reward_agent1}, Agent 2: {total_reward_agent2}\")\n",
    "\n",
    "    return best_path_agent1, best_path_agent2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Total Reward Agent 1: -100, Agent 2: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Tec\\multi_agentes\\multiagentes-TC2008B\\Q-learning_13_2agents.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m agent2 \u001b[39m=\u001b[39m QLearningAgent(env)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Train the agents\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m best_path_agent1, best_path_agent2 \u001b[39m=\u001b[39m train_agent(env, agent1, agent2, episodes\u001b[39m=\u001b[39;49mEPISODES)\n",
      "\u001b[1;32md:\\Tec\\multi_agentes\\multiagentes-TC2008B\\Q-learning_13_2agents.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m action_agent1 \u001b[39m=\u001b[39m agent1\u001b[39m.\u001b[39mchoose_action(state_agent1, neg_reward_agent1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m action_agent2 \u001b[39m=\u001b[39m agent2\u001b[39m.\u001b[39mchoose_action(state_agent2, neg_reward_agent2)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m (next_state_agent1, next_state_agent2), (reward_agent1, reward_agent2), done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action_agent1, action_agent2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m agent1\u001b[39m.\u001b[39mlearn(state_agent1, action_agent1, reward_agent1, next_state_agent1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m agent2\u001b[39m.\u001b[39mlearn(state_agent2, action_agent2, reward_agent2, next_state_agent2)\n",
      "\u001b[1;32md:\\Tec\\multi_agentes\\multiagentes-TC2008B\\Q-learning_13_2agents.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m y2, x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_agent2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_map[y1, x1] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m  \u001b[39m# Mark position for agent 1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreward_map[y2, x2] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m  \u001b[39m# Mark position for agent 2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Check if either agent is done\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m done \u001b[39m=\u001b[39m done_agent1 \u001b[39mor\u001b[39;00m done_agent2\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = GridEnv()\n",
    "\n",
    "# Create two agents\n",
    "agent1 = QLearningAgent(env)\n",
    "agent2 = QLearningAgent(env)\n",
    "\n",
    "# Train the agents\n",
    "best_path_agent1, best_path_agent2 = train_agent(env, agent1, agent2, episodes=EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animation_plot(state_agent1, state_agent2, env, ax):\n",
    "    # Update the reward map to reflect the agents' movement\n",
    "    env.reward_map[state_agent1[0], state_agent1[1]] = -1\n",
    "    env.reward_map[state_agent2[0], state_agent2[1]] = -1\n",
    "\n",
    "    ax.clear()\n",
    "    ax.imshow(env.reward_map, cmap=cmap, norm=norm, alpha=0.8)  # Use the custom colormap\n",
    "    ax.scatter(state_agent1[1], state_agent1[0], color='red', label='Agent 1', s=100)\n",
    "    ax.scatter(state_agent2[1], state_agent2[0], color='blue', label='Agent 2', s=100)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.legend()\n",
    "\n",
    "    \n",
    "def update(frame, best_path, env, ax):\n",
    "    best_path_agent1, best_path_agent2 = best_path\n",
    "    if frame < len(best_path_agent1):\n",
    "        state_agent1 = best_path_agent1[frame]\n",
    "        state_agent2 = best_path_agent2[frame]\n",
    "        animation_plot(state_agent1, state_agent2, env, ax)\n",
    "    else:\n",
    "        update.done = True  # Stop the animation when the end of the best path is reached\n",
    "\n",
    "colors = ['black', 'green', 'white', 'yellow']  # Replace with actual colors\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "# Define the boundaries for these values\n",
    "# The values are chosen to ensure that -100, -1, and 1 fall into separate bins\n",
    "bounds = [-200, -1, 1, 200]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\"\n",
       "href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css\">\n",
       "<script language=\"javascript\">\n",
       "  function isInternetExplorer() {\n",
       "    ua = navigator.userAgent;\n",
       "    /* MSIE used to detect old browsers and Trident used to newer ones*/\n",
       "    return ua.indexOf(\"MSIE \") > -1 || ua.indexOf(\"Trident/\") > -1;\n",
       "  }\n",
       "\n",
       "  /* Define the Animation class */\n",
       "  function Animation(frames, img_id, slider_id, interval, loop_select_id){\n",
       "    this.img_id = img_id;\n",
       "    this.slider_id = slider_id;\n",
       "    this.loop_select_id = loop_select_id;\n",
       "    this.interval = interval;\n",
       "    this.current_frame = 0;\n",
       "    this.direction = 0;\n",
       "    this.timer = null;\n",
       "    this.frames = new Array(frames.length);\n",
       "\n",
       "    for (var i=0; i<frames.length; i++)\n",
       "    {\n",
       "     this.frames[i] = new Image();\n",
       "     this.frames[i].src = frames[i];\n",
       "    }\n",
       "    var slider = document.getElementById(this.slider_id);\n",
       "    slider.max = this.frames.length - 1;\n",
       "    if (isInternetExplorer()) {\n",
       "        // switch from oninput to onchange because IE <= 11 does not conform\n",
       "        // with W3C specification. It ignores oninput and onchange behaves\n",
       "        // like oninput. In contrast, Microsoft Edge behaves correctly.\n",
       "        slider.setAttribute('onchange', slider.getAttribute('oninput'));\n",
       "        slider.setAttribute('oninput', null);\n",
       "    }\n",
       "    this.set_frame(this.current_frame);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.get_loop_state = function(){\n",
       "    var button_group = document[this.loop_select_id].state;\n",
       "    for (var i = 0; i < button_group.length; i++) {\n",
       "        var button = button_group[i];\n",
       "        if (button.checked) {\n",
       "            return button.value;\n",
       "        }\n",
       "    }\n",
       "    return undefined;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.set_frame = function(frame){\n",
       "    this.current_frame = frame;\n",
       "    document.getElementById(this.img_id).src =\n",
       "            this.frames[this.current_frame].src;\n",
       "    document.getElementById(this.slider_id).value = this.current_frame;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.next_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.previous_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.max(0, this.current_frame - 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.first_frame = function()\n",
       "  {\n",
       "    this.set_frame(0);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.last_frame = function()\n",
       "  {\n",
       "    this.set_frame(this.frames.length - 1);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.slower = function()\n",
       "  {\n",
       "    this.interval /= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.faster = function()\n",
       "  {\n",
       "    this.interval *= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_forward = function()\n",
       "  {\n",
       "    this.current_frame += 1;\n",
       "    if(this.current_frame < this.frames.length){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.first_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.last_frame();\n",
       "        this.reverse_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.last_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_reverse = function()\n",
       "  {\n",
       "    this.current_frame -= 1;\n",
       "    if(this.current_frame >= 0){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.last_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.first_frame();\n",
       "        this.play_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.first_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.pause_animation = function()\n",
       "  {\n",
       "    this.direction = 0;\n",
       "    if (this.timer){\n",
       "      clearInterval(this.timer);\n",
       "      this.timer = null;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.play_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = 1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function() {\n",
       "        t.anim_step_forward();\n",
       "    }, this.interval);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.reverse_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = -1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function() {\n",
       "        t.anim_step_reverse();\n",
       "    }, this.interval);\n",
       "  }\n",
       "</script>\n",
       "\n",
       "<style>\n",
       ".animation {\n",
       "    display: inline-block;\n",
       "    text-align: center;\n",
       "}\n",
       "input[type=range].anim-slider {\n",
       "    width: 374px;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "}\n",
       ".anim-buttons {\n",
       "    margin: 8px 0px;\n",
       "}\n",
       ".anim-buttons button {\n",
       "    padding: 0;\n",
       "    width: 36px;\n",
       "}\n",
       ".anim-state label {\n",
       "    margin-right: 8px;\n",
       "}\n",
       ".anim-state input {\n",
       "    margin: 0;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<div class=\"animation\">\n",
       "  <img id=\"_anim_imgde31d29d1292497ebe77554b83b1b60e\">\n",
       "  <div class=\"anim-controls\">\n",
       "    <input id=\"_anim_sliderde31d29d1292497ebe77554b83b1b60e\" type=\"range\" class=\"anim-slider\"\n",
       "           name=\"points\" min=\"0\" max=\"1\" step=\"1\" value=\"0\"\n",
       "           oninput=\"animde31d29d1292497ebe77554b83b1b60e.set_frame(parseInt(this.value));\">\n",
       "    <div class=\"anim-buttons\">\n",
       "      <button title=\"Decrease speed\" aria-label=\"Decrease speed\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.slower()\">\n",
       "          <i class=\"fa fa-minus\"></i></button>\n",
       "      <button title=\"First frame\" aria-label=\"First frame\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.first_frame()\">\n",
       "        <i class=\"fa fa-fast-backward\"></i></button>\n",
       "      <button title=\"Previous frame\" aria-label=\"Previous frame\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.previous_frame()\">\n",
       "          <i class=\"fa fa-step-backward\"></i></button>\n",
       "      <button title=\"Play backwards\" aria-label=\"Play backwards\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.reverse_animation()\">\n",
       "          <i class=\"fa fa-play fa-flip-horizontal\"></i></button>\n",
       "      <button title=\"Pause\" aria-label=\"Pause\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.pause_animation()\">\n",
       "          <i class=\"fa fa-pause\"></i></button>\n",
       "      <button title=\"Play\" aria-label=\"Play\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.play_animation()\">\n",
       "          <i class=\"fa fa-play\"></i></button>\n",
       "      <button title=\"Next frame\" aria-label=\"Next frame\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.next_frame()\">\n",
       "          <i class=\"fa fa-step-forward\"></i></button>\n",
       "      <button title=\"Last frame\" aria-label=\"Last frame\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.last_frame()\">\n",
       "          <i class=\"fa fa-fast-forward\"></i></button>\n",
       "      <button title=\"Increase speed\" aria-label=\"Increase speed\" onclick=\"animde31d29d1292497ebe77554b83b1b60e.faster()\">\n",
       "          <i class=\"fa fa-plus\"></i></button>\n",
       "    </div>\n",
       "    <form title=\"Repetition mode\" aria-label=\"Repetition mode\" action=\"#n\" name=\"_anim_loop_selectde31d29d1292497ebe77554b83b1b60e\"\n",
       "          class=\"anim-state\">\n",
       "      <input type=\"radio\" name=\"state\" value=\"once\" id=\"_anim_radio1_de31d29d1292497ebe77554b83b1b60e\"\n",
       "             >\n",
       "      <label for=\"_anim_radio1_de31d29d1292497ebe77554b83b1b60e\">Once</label>\n",
       "      <input type=\"radio\" name=\"state\" value=\"loop\" id=\"_anim_radio2_de31d29d1292497ebe77554b83b1b60e\"\n",
       "             checked>\n",
       "      <label for=\"_anim_radio2_de31d29d1292497ebe77554b83b1b60e\">Loop</label>\n",
       "      <input type=\"radio\" name=\"state\" value=\"reflect\" id=\"_anim_radio3_de31d29d1292497ebe77554b83b1b60e\"\n",
       "             >\n",
       "      <label for=\"_anim_radio3_de31d29d1292497ebe77554b83b1b60e\">Reflect</label>\n",
       "    </form>\n",
       "  </div>\n",
       "</div>\n",
       "\n",
       "\n",
       "<script language=\"javascript\">\n",
       "  /* Instantiate the Animation class. */\n",
       "  /* The IDs given should match those used in the template above. */\n",
       "  (function() {\n",
       "    var img_id = \"_anim_imgde31d29d1292497ebe77554b83b1b60e\";\n",
       "    var slider_id = \"_anim_sliderde31d29d1292497ebe77554b83b1b60e\";\n",
       "    var loop_select_id = \"_anim_loop_selectde31d29d1292497ebe77554b83b1b60e\";\n",
       "    var frames = new Array(2);\n",
       "    \n",
       "  frames[0] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\\\n",
       "bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9h\\\n",
       "AAAPYQGoP6dpAAAcRUlEQVR4nO3dfZTXdZ338ddvZmCGO2eCICWwMIlakita7Whb14bmzYqbdmGi\\\n",
       "q1e42UoasJq7ay6d+mO12lyPSV4VnZ2WqD0Jq2xymavXaTVbN12lDU28BzSMDFZiuBkGlpnf9cco\\\n",
       "OqkxDjC/wc/jcc6cA7/v9zfznhvm9+R7W6lWq9UAAFCMuloPAABA/xKAAACFEYAAAIURgAAAhRGA\\\n",
       "AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAA\\\n",
       "hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\\\n",
       "gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\\\n",
       "AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\\\n",
       "EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFaaj1ABycurq6sn79+owYMSKVSqXW4wDwGlWr\\\n",
       "1WzdujVjx45NXZ3tQaURgPTJ+vXrM378+FqPAcA+WrduXcaNG1frMehnApA+GTFiRJLkqC8dlfqm\\\n",
       "+hpP86K7/rTWEwAcHLZs6cz48T/f8/ucsghA+uSF3b71TfWpHzJwAvCQQ2o9AcDBxWE8ZbLTHwCg\\\n",
       "MAIQAKAwAhAAoDCOAQRgn1SrlezePTydnUOSOJ5sYKimvn5HGhq2pVKp1noYBiABCECf7drVkl/9\\\n",
       "6sNpb39HvKQMNLszdOijOeyw5Rk8eHOth2GA8a8VgD7p6qrP2rUXp77+zRk7dmgGD67ECaUDQ7Wa\\\n",
       "7NpVzcaNzVm7dlwmTvzb1NV11nosBhABCECf7No1Kl1dzRk/fliGDnVI+UAzZEgyaNCwPP10c3bt\\\n",
       "Gpmmpo21HokBRABSW9Vqmrd3ZmhHZ9qb6tM2rD42IcDBopKkEncRG7i6vzeVOOeT3yYAqYnh7btz\\\n",
       "2j3PZeadGzN+4849j68b3Zgl00bnluNGZdtQP55QjGo1eW5zsq09GT40GdXiP4NwAHmFpd8du6ot\\\n",
       "X164Jk07u1627M0bd+bTS5/JxTevz1/NPiL3Tm6uwYRAv9m8Jfn2zclX/zFZve7Fx982Ppl7bjLr\\\n",
       "9KTFLX5gf7NNmH517Kq2XHf9k2nc1ZW6vPwH8IXHGnd15brrn8yxq9r6f0igf9x+dzLu+OTSv03W\\\n",
       "PNNz2Zpnuh8fd3z3egfIPfesTH39UZk+/aID9jH25qmnfplKZXJWrnxkr+vOm/eF/P7vfzSNje/O\\\n",
       "u9/9v/phOl6vBCD9Znj77nx54ZqkmtTv5bJU9dUk1eTLC9dkePvufpkP6Ee3351MvyjZ0dG9+7f6\\\n",
       "W78UXnhsR0f3egcoAltbl2Xu3D/Jj3+8IuvXbzggH2N/+/jHP5KZM/+o1mNwkBOA9JvT7nkuTTu7\\\n",
       "9hp/L6ivJk07uzL93k0HdjCgf23eksy4pDvwuvbyC6Hr+RCccUn38/ajbdu2Z8mSf8lFF52d6dP/\\\n",
       "MIsWff9l6yxffkcmTvyjNDVNzbRp5+fb3/5+KpXJ2fySWe6++6f5wAf+d4YMeU/Gjz8h8+Z9Idu3\\\n",
       "t+9Z/ta3npgvfOGb+fjHP5sRI47J4YefkG9+c+me5RMmnJQkmTr1zFQqk/PBD57/qjMvWPDX+dSn\\\n",
       "/iRHHDFu378AFE0A0j+q1cy8s2+XIDj7jg0v3zoAHLy+fXPS3rH3+HtBV7V7/cXL9+sYS5fenne8\\\n",
       "Y0ImTZqQ8847Ld/61rJUX/K7Zu3aZ3LmmZfmjDNOyAMPLMvs2Wdl/vwFPd7H6tW/yCmnzM6MGSfm\\\n",
       "wQf/OUuW/F3uvvs/M2fOVT3Wu+aaRTn66Mn52c9uzMUXn52LLvqbPPbY2iTJfffdkCT54Q9b86tf\\\n",
       "/SjLln1lv36e8EoEIP2ieXtnxm/c+Zp/4OqSjN+4M83bXcAUXheq1e4TPvpiwXf3638GW1tvynnn\\\n",
       "/XGS5JRT3p+2tm2566779yxfuHBpJk2akKuv/otMmjQhZ599as4///Qe7+OLX/z7nHvuabnkko9l\\\n",
       "4sS35H3vm5oFC67I4sXL09Hx4hUOTj31f+bii8/JkUe+JZdf/om88Y1vyJ133pckGT16ZJJk1Kjm\\\n",
       "HHro6Iwc2bLfPkd4NQKQfjG0Y98Cbl+fDwwQz23uPtv3tYZctdr9vE3758Swxx5bm/vueyjnnHNq\\\n",
       "kqShoSEzZ56S1tZlL1nnqRxzzLt6PO+97z2qx98feODRLFr0/QwffvSet5NPnp2urq6sXfviiS1T\\\n",
       "prx9z58rlUoOPXRUNmx4br98LtAXLgNDv2hvqq/p84EBYlv73tf5XbZu775G4D5qbb0pu3fvztix\\\n",
       "0/Y8Vq1W09g4ONdfPz/NzSN69X62bduR2bPPyrx5575s2eGHH7bnz4MG9Xy5rVQq6ertLnA4AAQg\\\n",
       "/aJtWH3WjW7Mm1/jbuCuJL8c3dh9hxDg4Dd86L49f8SwfR5h9+7dWbx4ea655i9z0kl/0GPZGWfM\\\n",
       "zfe+d2s++cmZmTTprbn11n/rsfz++x/q8ff3vOedefjh1TnyyLf0eZ7BgwclSTo7X35tVDhQ7AKm\\\n",
       "f1QqWTJtdJ+eesPxY9wRAF4vRrV0X+T5tf6brlS6nzdy3y8Of8std+U3v9mSCy6YkXe9a2KPtxkz\\\n",
       "Tkxr601Jktmzz8qjj67J5Zdfk8cffypLl96WRYtufn6c7vkvv/yC/OQnKzNnzpVZufKRPPHE07n5\\\n",
       "5jsyZ86VvZ5nzJiRGTKkKbfddnd+/ev/Slvb1ldd98knn87KlY/k2Wf/Kzt27MzKlY9k5cpHsmvX\\\n",
       "rn34ilAiAUi/ueW4UelorEtnL3/vd1aSjsa6/ODYkQd2MKD/VCrdd/joi3nn7Zf/DLa23pQPfei4\\\n",
       "V9zNO2PGiVmxYlUefPCxTJgwLjfeeG2WLfthpkz5SL7+9Rsyf/6FSZLGxsFJkilTJuWuuxbl8cef\\\n",
       "zgc+8LFMnTojn/vcVzN27Jhez9PQ0JAFC67IwoVLM3bstJx++txXXfcTn/h8pk49MwsXLs3jjz+V\\\n",
       "qVPPzNSpZ2b9+r5dZYFyVapV19fgtduyZUuam5vz7q+8O/VDer979oU7geztYtCd3feYz7y5E/Mf\\\n",
       "v9f720CtuLDXqwL7qKPjTVm79rJMmDAmTU2vYXvC5i3dd/jY0ctLwdTVJUMak2fuqPlt4a66amG+\\\n",
       "8Y2lWbfuX2s6R291dHRl7doNmTDhmjQ1/brHsi1bOtPcvDJtbW055BC32yuNLYD0q3snN+fP5xyZ\\\n",
       "nYPr0pXuY/xe6oXHdg6ue83xBxwkWg5JbvpK99a8ur1s0aurJJUky66rSfx97Wvfy/33/zxr1qzL\\\n",
       "d76zPFdf/Q+ZNevD/T4H7G9OAqHf3Tu5Oad+6ahMv3dTzr5jQ8ZvfPFaWb8c3Zgbjh+TW44ble2v\\\n",
       "YcsicJA5+f3JD77efYeP9o7ux166Q+qFXb1Dmrrj77dO1ugvTzzxdK68cmE2bWrL4Ycflssum5Ur\\\n",
       "rvizmswC+5MApCa2DW3IkuPHZMm00Wne3pmhHZ1pb6rvPtvXCR9QhpPf371bd/Hy7os8r1734rIj\\\n",
       "xnUf8zfr9KSXl2Q5EK699jO59trP1Ozjw4EiAKmtSiVtwxvSNtyPIhSp5ZDu0Jt7bvdFnrdu777U\\\n",
       "y8hm/xmEA8irLgC1V6l0XyJmP1zkGdg7J4EAABRGAAIAFEYAAgAUxjGAANRctZo891x9tm2ry/Dh\\\n",
       "XRk1qtM5IHAA2QIIQM1s3lyX664bmYkTj8zo0ZMyYcLEjB49KRMnHpnrrhuZzZu9TMGB4F8WADVx\\\n",
       "++3DMm7c23PppW/KmjWDeixbs2ZQLr30TRk37u25/fZhB2yGe+5Zmfr6ozJ9+kUH7GPszVNP/TKV\\\n",
       "yuSsXPnI71zvgQcezTnn/EXGjz8hQ4a8J+985x/nuuu+009T8nojAAHod7ffPizTpx+eHTsqqVa7\\\n",
       "317qhcd27Khk+vTDD1gEtrYuy9y5f5If/3hF1q/fcEA+xv7y058+nDFjRuW73/1SVq26OfPnX5gr\\\n",
       "rvhKrr/+H2s9GgehSrVa7cWduKGnLVu2pLm5OW1t784hh7hlG5Soo+NNWbv2skyYMCZNTb3fnrB5\\\n",
       "c13GjXt7duyopKtr7wf61dVVM2RINc8883haWn77DuJ9t23b9hx22AezYsXSfP7z/ydTprw9f/3X\\\n",
       "F/ZYZ/nyO3LZZVdn3bpnc9xx/yPnn39Gzj9/fn7zm3vS8vy9ie+++6e54oqvZMWKVXnjG9+Qj3zk\\\n",
       "hHzxi5dk2LChSZK3vvXEXHjhR/Pkk7/IP/3T7XnDGw7JZz87OxdeeFaSpFKZ3ONj/uEfHpMf/WhR\\\n",
       "rz6HT33qb/LII2tyxx3/8IrLOzq6snbthkyYcE2amn7dY9mWLZ1pbl6Ztra2HHKI+66XxhZAAPrV\\\n",
       "t7/dkvb23sVfknR1VdLeXsnixS37dY6lS2/PO94xIZMmTch5552Wb31rWV66TWTt2mdy5pmX5owz\\\n",
       "TsgDDyzL7NlnZf78BT3ex+rVv8gpp8zOjBkn5sEH/zlLlvxd7r77PzNnzlU91rvmmkU5+ujJ+dnP\\\n",
       "bszFF5+diy76mzz22NokyX333ZAk+eEPW/OrX/0oy5Z9pdefQ1vbtowc2dzHrwAlE4AA9JtqNfnq\\\n",
       "V0f26bkLFozM/txn1dp6U84774+TJKec8v60tW3LXXfdv2f5woVLM2nShFx99V9k0qQJOfvsU3P+\\\n",
       "+af3eB9f/OLf59xzT8sll3wsEye+Je9739QsWHBFFi9eno6OnXvWO/XU/5mLLz4nRx75llx++Sfy\\\n",
       "xje+IXfeeV+SZPTo7q/HqFHNOfTQ0Rk5sqVX8//kJz/LkiW35cILP7ovXwYKJQAB6DfPPVef1asH\\\n",
       "v+yYv72pVitZvXpwNm3aP4ecPPbY2tx330M555xTkyQNDQ2ZOfOUtLYue8k6T+WYY97V43nvfe9R\\\n",
       "Pf7+wAOPZtGi72f48KP3vJ188ux0dXVl7dpn9qw3Zcrb9/y5Uqnk0ENHZcOG5/o8/0MPPZHTT5+b\\\n",
       "z3/+opx00h/0+f1QLtcBBKDfbNu2b9sdtm6ty6hRnfs8R2vrTdm9e3fGjp2257FqtZrGxsG5/vr5\\\n",
       "aW4e0av3s23bjsyefVbmzTv3ZcsOP/ywPX8eNKjny22lUklXV982Zz788JM54YQLcuGFH81nP/vJ\\\n",
       "Pr0PEIAA9Jvhw/ftJI4RI/b9JJDdu3dn8eLlueaav3zZ1rMzzpib733v1nzykzMzadJbc+ut/9Zj\\\n",
       "+f33P9Tj7+95zzvz8MOrc+SRb+nzPIMHd18Cp7Nz75/bqlVP5vjjP55Zsz6cq6768z5/TLALGIB+\\\n",
       "M2pUZ972tl2pVF7b1q9KpZq3vW1XRo7c961/t9xyV37zmy254IIZede7JvZ4mzHjxLS23pQkmT37\\\n",
       "rDz66Jpcfvk1efzxp7J06W1ZtOjm5+fp3oV9+eUX5Cc/WZk5c67MypWP5Iknns7NN9+ROXOu7PU8\\\n",
       "Y8aMzJAhTbnttrvz61//V9ratr7ieg899ESmTfvTnHTS+/LpT8/Ks89uzLPPbszGjZv28StCiQQg\\\n",
       "AP2mUknmzu1bsMybt2m/3B6utfWmfOhDx73ibt4ZM07MihWr8uCDj2XChHG58cZrs2zZDzNlykfy\\\n",
       "9a/fkPnzuy8T09g4OEkyZcqk3HXXojz++NP5wAc+lqlTZ+Rzn/tqxo4d0+t5GhoasmDBFVm4cGnG\\\n",
       "jp2W00+f+4rr3Xjj/8vGjZvy3e/+3xx22Af3vB1zzMw+fBUonesA0ieuAwgc7NcB7IurrlqYb3xj\\\n",
       "adat+9eaztFbrgPIq7EFEIB+1dLSlZtuWpdKpTvufpe6umoqlWTZsnU1ib+vfe17uf/+n2fNmnX5\\\n",
       "zneW5+qr/yGzZn243+eA/c1JIAD0u5NP3p4f/OAXmTFjfNrbux976aVhXjhGcMiQapYtW5eTTtpe\\\n",
       "izHzxBNP58orF2bTprYcfvhhueyyWbniij+rySywPwlAAGri5JO355lnHs/ixS1ZsGBkVq8evGfZ\\\n",
       "EUf8d+bN25RZszanubl2u32vvfYzufbaz9Ts48OBIgABqJmWlq7Mm7cpc+duyqZN9dm6tS4jRnRl\\\n",
       "5MjO/XLCB/DKBCAANVepdF8iZn9c5BnYOyeBANBH1STV/Xp/Xvav7u9N9fk3eJEABKBPBg3akmR3\\\n",
       "2ttre2kWXl3392Z3Bg1qq/UoDDB2AQPQJ/X1HWlp+fds2PChJC0ZOrTOcXsDRLXaHX8bNmxOS8u/\\\n",
       "p75+Z61HYoARgAD02aGH/kuSZMOGP0j3S4oCHBiqSXanpeXf93yP4KUEIAB9VqlUc9hht2bMmH/N\\\n",
       "f/93cwTgQFHNoEFttvzxqgQgAPusvn5n6us31HoMoJecBAIAUBgBCABQGAEIAFAYAQgAUBgBCABQ\\\n",
       "GAEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgB\\\n",
       "CABQmIZaDwAAJTj66FpP0FNnZ60noJZsAQQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQA\\\n",
       "KIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiM\\\n",
       "AAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAE\\\n",
       "ACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEAChMQ60HAIASrFhR6wl62rIlaW6u9RTUii2A\\\n",
       "AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAA\\\n",
       "hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\\\n",
       "gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\\\n",
       "AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\\\n",
       "EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGA\\\n",
       "AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAA\\\n",
       "hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\\\n",
       "gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\\\n",
       "AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\\\n",
       "EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGA\\\n",
       "AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAA\\\n",
       "hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\\\n",
       "gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\\\n",
       "AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\\\n",
       "EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGA\\\n",
       "AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAA\\\n",
       "hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\\\n",
       "gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\\\n",
       "AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\\\n",
       "EYAAAIURgAAAhRGAAACFEYAAAIVpqPUAAFCCo79Z6wl66txR6wmoJVsAAQAKIwABAAojAAEACiMA\\\n",
       "AQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAK41ZwAHAQqFaTzu3N6ewYmvqm9tQPa0ul\\\n",
       "UuupOFgJQAAYwHa3D89z95yWjXfOzM6N4/c83jh6XUZPW5JRx92ShqHbajghByMBCAADVNuqY7Nm\\\n",
       "4ZfTtbPpZct2bnxznln66ay/+eIcMfuv0jz53hpMyMHKMYAAMAC1rTo2T15/Xbp2Nab75fq3X7K7\\\n",
       "H+va1Zgnr78ubauO7f8hOWgJQAAYYHa3D8+ahV9Oqkmq9b975Wp9Uk3WLPxydrcP75f5OPgJQAAY\\\n",
       "YJ6757Tu3b57i78XVOvTtbMpm+6dfmAH43VDAALAAFKtJhvvnNmn52644+xUq/t5IF6XBCAADCCd\\\n",
       "25ufP9v3tb5E12XnxvHp3N58IMbidUYAAsAA0tkxtKbPpwwCEAAGkPqm9po+nzIIQAAYQOqHtaVx\\\n",
       "9LokXa/xmV1pHL0u9cPaDsRYvM4IQAAYQCqVZPS0JX167pjjb3B7OHpFAALAADPquFtS19iRVDp7\\\n",
       "94RKZ+oaOzLy2B8c2MF43RCAADDANAzdliNm/1VSyd4jsNKZVJK3ffIv3ROYXhOAADAANU++N0fO\\\n",
       "+fPUDd6Z7uMBf/uYwO7H6gbvzMS583LI7/1H/w/JQauh1gMAAK+sefK9OepLp2bTvdOz4Y6zn78+\\\n",
       "YLfG0b/MmONvyKjjbkn9kO01nJKDkQAEgAGsYei2jDl+SUZPW5LO7c3p7Bia+qb21A9rc8IHfSYA\\\n",
       "AeAgUKkkDcPb0jDcZV7Yd44BBAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojOsA0ifV\\\n",
       "ajVJsmVLL29UDlC4zh21nqCnzo7u398v/D6nLAKQPtm6dWuSZPz4n9d4EgD2xdatW9Pc3FzrMehn\\\n",
       "lar0pw+6urqyfv36jBgxIhX3IgI46FSr1WzdujVjx45NXZ0jwkojAAEACiP5AQAKIwABAAojAAEA\\\n",
       "CiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAoj\\\n",
       "AAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwAB\\\n",
       "AAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAK\\\n",
       "IwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAAEACiMA\\\n",
       "AQAKIwABAArz/wF9tiBi6wkuUgAAAABJRU5ErkJggg==\\\n",
       "\"\n",
       "  frames[1] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\\\n",
       "bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9h\\\n",
       "AAAPYQGoP6dpAAAbB0lEQVR4nO3df3CV9b3g8c9Jwo8gEBYKRZZQg1Da1TLFaqf1rqtUK660V3fj\\\n",
       "LbqyxWJXhEJurb2X69jp/WPV3qnLtKLTFmfTAnbHwihbXeuVHW9dula7YNfgqldBQC8UFSpNIPyQ\\\n",
       "kpz940iuUSshJJzEz+s1kyE55zk5nyRMzjvf55znKRSLxWIAAJBGRbkHAADg5BKAAADJCEAAgGQE\\\n",
       "IABAMgIQACAZAQgAkIwABABIRgACACQjAAEAkhGAAADJCEAAgGQEIABAMgIQACAZAQgAkIwABABI\\\n",
       "RgACACQjAAEAkhGAAADJCEAAgGQEIABAMgIQACAZAQgAkIwABABIRgACACQjAAEAkhGAAADJCEAA\\\n",
       "gGQEIABAMgIQACAZAQgAkIwABABIRgACACQjAAEAkhGAAADJCEAAgGQEIABAMgIQACAZAQgAkIwA\\\n",
       "BABIRgACACQjAAEAkhGAAADJCEAAgGQEIABAMgIQACAZAQgAkIwABABIRgACACQjAAEAkhGAAADJ\\\n",
       "CEAAgGQEIABAMgIQACAZAQgAkIwABABIRgACACRTVe4ByKu9vT127twZw4YNi0KhUO5xAPqNYrEY\\\n",
       "+/bti3HjxkVFhbUcjp8ApGx27twZtbW15R4DoN/avn17jB8/vtxj0A8JQMpm2LBhEVH6BTZ8+PAy\\\n",
       "TwPQf+zduzdqa2s7fo/C8RKAlM3R3b7Dhw8XgADd4OkzdJcnDgAAJCMAAQCSEYAAAMl4DiBAYsVi\\\n",
       "MY4cORJtbW3lHoW3qaysjKqqKs/xo9cIQICkDh8+HK+++mocOHCg3KPwHoYMGRKnnnpqDBw4sNyj\\\n",
       "8AEkAAESam9vj23btkVlZWWMGzcuBg4caLWpjygWi3H48OHYvXt3bNu2LSZPnuxgz/Q4AUj/VSxG\\\n",
       "vPFGRGtrxNChEaNGRXgAgy45fPhwtLe3R21tbQwZMqTc4/AO1dXVMWDAgHjllVfi8OHDMXjw4HKP\\\n",
       "xAeMPynof5qbI+64I2Ly5IjRoyPq6kr/Tp5cury5udwTQr9hZanv8rOhN/nfRf+ydm3E+PERN9wQ\\\n",
       "sXVr5+u2bi1dPn58aTvg5CgWI37/+4iXXy79WyyWeyLgGAQg/cfatREzZ0YcPFh6gHnng8zRyw4e\\\n",
       "LG0nAqF3WY2HfksA0j80N0fU15cCr739/bdtby9tV1/vAQh6Sx9YjX/yySejsrIyZs6c2Wv3cSwv\\\n",
       "v/xyFAqFaGpqOua2DQ0N8alPfSoGDRoUn/zkJ3t9Nng/ApD+YcWKiAMHjh1/R7W3l7ZfubJ354KM\\\n",
       "+shqfGNjYyxatCh+9atfxc6dO3vlPnra3LlzY9asWeUeAwQg/UCxGHHnnd277dKlno8EPamPrMa3\\\n",
       "trbGqlWrYv78+TFz5sxYvnz5u7Z58MEHY/LkyTF48OCYPn16rFixIgqFQjS/bZbHH388zjvvvKiu\\\n",
       "ro7a2tpoaGiI/fv3d1x/2mmnxW233RZz586NYcOGxYQJE+Luu+/uuL6uri4iIqZNmxaFQiEuuOCC\\\n",
       "Pznz0qVL42tf+1pMnDjxhL9+OFECkL7vjTcitmw5/pArFku327Ond+aCjPrIavzq1avjYx/7WEyZ\\\n",
       "MiVmz54dP/7xj6P4tt8R27ZtiyuuuCIuv/zy2LhxY8ybNy9uvvnmTp9jy5Ytcckll0R9fX0888wz\\\n",
       "sWrVqnj88cdj4cKFnbZbsmRJnH322fH000/HggULYv78+fHiiy9GRMT69esjIuLRRx+NV199Ndas\\\n",
       "WdOjXyf0FgFI39faemK337evZ+aA7PrQanxjY2PMnj07IiIuueSSaGlpiXXr1nVcv2zZspgyZUrc\\\n",
       "fvvtMWXKlLjyyivjmmuu6fQ5vvOd78TVV18dX//612Py5Mlx7rnnxtKlS2PlypVx6NChju0uvfTS\\\n",
       "WLBgQUyaNCkWL14cH/rQh+Kxxx6LiIjRo0dHRMSoUaNi7NixMXLkyB77GqE3CUD6vqFDT+z2w4b1\\\n",
       "zByQXR9ZjX/xxRdj/fr1cdVVV0VERFVVVcyaNSsaGxs7bXPOOed0ut2nP/3pTh9v3Lgxli9fHkOH\\\n",
       "Du14mzFjRsdZUo6aOnVqx/uFQiHGjh0bu3bt6pGvBcrFmUDo+0aNijj99NIrC4/ngadQiJg4McJf\\\n",
       "5NAzemI1ftSoEx6jsbExjhw5EuPGjeu4rFgsxqBBg+Kuu+6KmpqaLn2e1tbWmDdvXjQ0NLzrugkT\\\n",
       "JnS8P2DAgE7XFQqFaO/qLnDoowQgfV+hELFoUemwEserocHp4aCn9IHV+CNHjsTKlStjyZIlcfHF\\\n",
       "F3e67vLLL4977703rr/++pgyZUo8/PDDna7fsGFDp4/POuuseP7552PSpEndnmfgwIEREdHW1tbt\\\n",
       "zwHlYBcw/cOcORFDhkR09dRIFRWl7b/85d6dCzI5uhp/vH9UFQql2/XAavxDDz0Uf/jDH+Laa6+N\\\n",
       "M888s9NbfX19x27gefPmxQsvvBCLFy+OTZs2xerVqzteKVx4a/7FixfHE088EQsXLoympqbYvHlz\\\n",
       "PPDAA+96Ecj7GTNmTFRXV8cjjzwSr7/+erS0tPzJbV966aVoamqK1157LQ4ePBhNTU3R1NQUhw8f\\\n",
       "7v43BLpJANI/jBgRcf/9pQeSY0VgRUVpuzVrSrcDesbR1fju6KHV+MbGxrjoooveczdvfX19PPXU\\\n",
       "U/HMM89EXV1d3HfffbFmzZqYOnVq/PCHP+x4FfCgQYMiovTcvnXr1sWmTZvivPPOi2nTpsW3v/3t\\\n",
       "TruWj6WqqiqWLl0ay5Yti3HjxsVll132J7f96le/GtOmTYtly5bFpk2bYtq0aTFt2rR+cwxDPlgK\\\n",
       "xaKDpFEee/fujZqammhpaYnhw4d37UZr15aOKXbgQOnjt//3PfrgMmRIKf7esXsI+GeHDh2Kbdu2\\\n",
       "RV1dXQwePLjrN2xuLp3h4+DBrh0KpqIioro6YseOsv9Bduutt8aPfvSj2L59e1nn6Kr3+xl16/cn\\\n",
       "vI0VQPqXGTNKDyTf/37pBR5vN3Fi6fLf/U78QW/pR6vxP/jBD2LDhg2xdevWuOeee+L222+POXPm\\\n",
       "nPQ5oC/yIhD6nxEjSruTFi0qHVZi377Sk8tHjvSCDzgZZsyI+MUvjr0aX11d1tX4zZs3xy233BJ7\\\n",
       "9uyJCRMmxI033hg33XRTWWaBvsYuYMrGLgwon27vAn675ubSGT6WLi0d5++o008v/ZE2Z05EFw/J\\\n",
       "wrvZBUxvsgIIQPdYjYd+SwACcGIKhdIhYnrgIM/AyeFFIAAAyQhAAIBkBCAAQDKeAwjACSkWI954\\\n",
       "I6K1tXS64FGjvAYE+joBSNmd/5Pzo7K6smz3/9R1ZbtrKKMPR8SNEdEW3d0Z1NxcEStWjIg77xwZ\\\n",
       "W7YM7Lj89NMPx6JFe2LOnOYYMaILZwvhT2iPiF0R8c2IeP0d17Wd/HH4QLELGIDjtnbtKTF+/Efj\\\n",
       "hhs+HFu3Duh03datA+KGGz4c48d/NNauPaXXZnjyyaaorPxEzJw5v9fu41hefvl3USicEU1N//i+\\\n",
       "223c+EJcddU3o7b2wqiuPis+/vEvxh133HOSpoR3E4AAHJe1a0+JmTMnxMGDhSgWS29vd/SygwcL\\\n",
       "MXPmhF6LwMbGNbFo0X+IX/3qqdi5c1ev3EdP+e1vn48xY0bFT3/6d/Hccw/EzTdfFzfd9P24667/\\\n",
       "Vu7RSEoAAtBlzc0VUV9fG8ViRHv7+z/Rr729EMViRH19bTQ39+zDTWvr/li16u9j/vwrY+bM82P5\\\n",
       "8p+/a5sHH/xlTJ78b2Pw4Gkxffo1sWLFz6NQOCOam/d2bPP447+N8877j1FdfVbU1l4YDQ23xf79\\\n",
       "BzquP+20z8dtt90dc+d+K4YNOycmTLgw7r57dcf1dXWl09xNm3ZFFApnxAUXXPOe886d++/jjjtu\\\n",
       "ivPPPycmTqyN2bO/GF/5yuWxZs2jPfMNgeMkAAHoshUrRsSBA4Vjxt9R7e2FOHCgECtXjujROVav\\\n",
       "Xhsf+1hdTJlSF7NnfyF+/OM18fYzm27btiOuuOKGuPzyC2PjxjUxb96X4uabl3b6HFu2/FNccsm8\\\n",
       "qK//fDzzzH+PVav+Szz++P+NhQtv7bTdkiXL4+yzz4inn74vFiy4MubP/8/x4ovbIiJi/fqfRUTE\\\n",
       "o482xquv/q9Ys+b7Xf4aWlpaY+RIp8qjPAQgAF1SLEbceefIbt126dKR0ZNnnm9svD9mz/5iRERc\\\n",
       "csm/jpaW1li3bkPH9cuWrY4pU+ri9tu/GVOm1MWVV14a11xzWafP8Z3v/Ne4+uovxNe//uWYPPkj\\\n",
       "ce6502Lp0pti5coH49ChNzu2u/TSfxMLFlwVkyZ9JBYv/mp86EP/Ih57bH1ERIweXfp+jBpVE2PH\\\n",
       "jo6RI0d0af4nnng6Vq16JK677i9O5NsA3SYAAeiSN96ojC1bBr7rOX/HUiwWYsuWgbFnT8+82v/F\\\n",
       "F7fF+vXPxlVXXRoREVVVVTFr1iXR2Ljmbdu8HOecc2an233605/o9PHGjS/E8uU/j6FDz+54mzFj\\\n",
       "XrS3t8e2bTs6tps69aMd7xcKhRg7dlTs2vVGt+d/9tnNcdlli+Jv/3Z+XHzxn3X788CJcBgYALqk\\\n",
       "tfXE1gz27auIUaNO/PAljY33x5EjR2LcuOkdlxWLxRg0aGDcddfNUVMzrEufp7X1YMyb96VoaLj6\\\n",
       "XddNmHBqx/sDBnR+qCwUCtHe3r3lzOeffykuvPDauO66v4hvfev6bn0O6AkCEIAuGTr0xI7pN2zY\\\n",
       "iR8T8MiRI7Fy5YOxZMlfvWv17PLLF8W99z4c118/K6ZMOS0efvh/d7p+w4ZnO3181lkfj+ef3xKT\\\n",
       "Jn2k2/MMHFg6BE5b27G/tueeeyk+97m5MWfOn8ett/5lt+8TeoJdwAB0yahRbXH66YejUDi+1a9C\\\n",
       "oRinn344Ro488dW/hx5aF3/4w9649tr6OPPMyZ3e6us/H42N90dExLx5X4oXXtgaixcviU2bXo7V\\\n",
       "qx+J5csfeGue0i7sxYuvjSeeaIqFC2+JpqZ/jM2bX4kHHvhlLFx4S5fnGTNmZFRXD45HHnk8Xn/9\\\n",
       "99HSsu89t3v22c0xffpX4uKLz41vfGNOvPba7njttd2xe/eeE/yOQPcIQAC6pFCIWLSoe8HS0LCn\\\n",
       "R04P19h4f1x00Wffczdvff3n46mnnotnnnkx6urGx333fS/WrHk0pk79d/HDH/4sbr65dNqfQYNK\\\n",
       "Zy2ZOnVKrFu3PDZteiXOO+/LMW1afXz723fGuHFjujxPVVVVLF16UyxbtjrGjZsel1226D23u+++\\\n",
       "/xm7d++Jn/70f8Spp17Q8XbOObO68V2AE1coFnvydVnQdXv37o2ampr45Pc/6VRwcJIdOvTh2Lbt\\\n",
       "xqirGxODB3d9LaC5uSLGj/9oHDzYtUPBVFQUo7q6GDt2bCr7aeFuvXVZ/OhHq2P79n8o6xxddehQ\\\n",
       "e2zbtivq6pbE4MGdTwW3d29b1NQ0RUtLSwwfPrxME9KfWQEEoMtGjGiP++/fHoVCKe7eT0VFMQqF\\\n",
       "iDVrtpcl/n7wg3tjw4b/F1u3bo977nkwbr/9JzFnzp+f9DmgL/IiEACOy4wZ++MXv/inqK+vjQNv\\\n",
       "nTTj7YeGOfocwerqYqxZsz0uvnh/OcaMzZtfiVtuWRZ79rTEhAmnxo03zombbvpPZZkF+hoBCMBx\\\n",
       "mzFjf+zYsSlWrhwRS5eOjC1bBnZcN3HiH6OhYU/MmdMcNTXl2+37ve/9TXzve39TtvuHvkwAAtAt\\\n",
       "I0a0R0PDnli0aE/s2VMZ+/ZVxLBh7TFyZFuPvOAD6D0CEIATUiiUDhHTEwd5Bk4OLwIBSKkYEcUe\\\n",
       "PT8vPav0sym+9QY9SwACJDRgwN6IOBIHDpT30Cz8aaWfzZEYMKCl3KPwAWQXMEBClZWHYsSIX8eu\\\n",
       "XRdFxIgYMqTC8/b6iGKxFH+7djXHiBG/jsrKN8s9Eh9AAhAgqbFj/z4iInbt+rMoPRwowL6hGBFH\\\n",
       "YsSIX3f8jKCnCUCApAqFYpx66sMxZsw/xB//WBMCsK8oxoABLVb+6FUCECC5yso3o7JyV7nHAE4i\\\n",
       "LwIBAEhGAAIAJCMAAQCSEYAAAMkIQACAZAQgAEAyAhAAIBkBCACQjAAEAEhGAAIAJCMAAQCScS5g\\\n",
       "ym7dVyKGDy/3FACQhxVAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBk\\\n",
       "BCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQA\\\n",
       "SEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyVSV\\\n",
       "ewAA6E/OPrvcE0S0tZV7Avo7K4AAAMkIQACAZAQgAEAyAhAAIBkBCACQjAAEAEhGAAIAJCMAAQCS\\\n",
       "EYAAAMkIQACAZAQgAEAyAhAAIBkBCACQjAAEAEhGAAIAJCMAAQCSEYAAAMkIQACAZAQgAEAyAhAA\\\n",
       "IBkBCACQjAAEAEhGAAIAJCMAAQCSEYAAAMkIQACAZAQgAEAyAhAAIBkBCACQjAAEAEhGAAIAJCMA\\\n",
       "AQCSEYAAAMlUlXsAAOhPnnqq3BNE7N0bUVNT7inoz6wAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDIC\\\n",
       "EAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAk\\\n",
       "IwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAA\\\n",
       "QDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYA\\\n",
       "AgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBk\\\n",
       "BCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQA\\\n",
       "SEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhA\\\n",
       "AIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCM\\\n",
       "AAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAA\\\n",
       "yQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEI\\\n",
       "AJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIR\\\n",
       "gAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAg\\\n",
       "GQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwAB\\\n",
       "AJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDIC\\\n",
       "EAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJBMVbkHAID+5Oy7\\\n",
       "yz1BRNvBck9Af2cFEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDIOBA0AJ0mx\\\n",
       "GNG2vybaDg2JysEHovKUligUyj0VGQlAAOhlRw4MjTee/ELsfmxWvLm7tuPyQaO3x+jpq2LUZx+K\\\n",
       "qiGtZZyQbAQgAPSiluc+E1uXfTfa3xz8ruve3P0vY8fqb8TOBxbExHl/HTVn/KYME5KR5wACQC9p\\\n",
       "ee4z8dJdd0T74UFResh958Nu6bL2w4PipbvuiJbnPnPyhyQlAQgAveDIgaGxddl3I4oRUax8/42L\\\n",
       "lRHFiK3LvhtHDgw9KfORmwAEgF7wxpNfKO32PVb8HVWsjPY3B8ee38zs3cEgBCAA9LhiMWL3Y7O6\\\n",
       "ddtdv7wyisUeHgjeQQACQA9r21/z1qt9j/dhtiLe3F0bbftremMs6CAAAaCHtR0aUtbbw7EIQADo\\\n",
       "YZWDD5T19nAsAhAAeljlKS0xaPT2iGg/zlu2x6DR26PylJbeGAs6CEAA6GGFQsTo6au6ddsxn/uZ\\\n",
       "08PR6wQgAPSCUZ99KCoGHYootHXtBoW2qBh0KEZ+5he9OxiEAASAXlE1pDUmzvvriEIcOwILbRGF\\\n",
       "iNOv/yvnBOakEIAA0EtqzvhNTFr4l1Ex8M0oPR/wnc8JLF1WMfDNmLyoIYb/q/9z8ockpapyDwAA\\\n",
       "H2Q1Z/wmPvF3l8ae38yMXb+88q3jA5YMGv27GPO5n8Wozz4UldX7yzgl2QhAAOhlVUNaY8znVsXo\\\n",
       "6auibX9NtB0aEpWDD0TlKS1e8EFZCEAAOEkKhYiqoS1RNdRhXigvzwEEAEhGAAIAJCMAAQCSEYAA\\\n",
       "AMkIQACAZAQgAEAyDgND2Z3/k4jK6vLd/1PXle++AaAcrAACACQjAAEAkhGAAADJCEAAgGQEIABA\\\n",
       "MgIQACAZAQgAkIwABABIRgACACQjAAEAkhGAAADJCEAAgGQEIABAMgIQACAZAQgAkIwABABIRgAC\\\n",
       "ACQjAAEAkhGAAADJCEAAgGQEIABAMgIQACAZAQgAkIwABABIRgACACQjAAEAkhGAAADJCEAAgGQE\\\n",
       "IABAMgIQACAZAQgAkIwABABIpqrcA5BXsViMiIi2Q21lnWPv3rLePdDPtB0s9wT//Hvz6O9ROF6F\\\n",
       "ov89lMmOHTuitra23GMA9Fvbt2+P8ePHl3sM+iEBSNm0t7fHzp07Y9iwYVEoFMo9DkC/USwWY9++\\\n",
       "fTFu3LioqPBsLo6fAAQASMafDQAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIR\\\n",
       "gAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAg\\\n",
       "GQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwAB\\\n",
       "AJIRgAAAyQhAAIBkBCAAQDICEAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBkBCAAQDIC\\\n",
       "EAAgGQEIAJCMAAQASEYAAgAkIwABAJIRgAAAyQhAAIBk/j/atAwgxqp4ZQAAAABJRU5ErkJggg==\\\n",
       "\"\n",
       "\n",
       "\n",
       "    /* set a timeout to make sure all the above elements are created before\n",
       "       the object is initialized. */\n",
       "    setTimeout(function() {\n",
       "        animde31d29d1292497ebe77554b83b1b60e = new Animation(frames, img_id, slider_id, 100.0,\n",
       "                                 loop_select_id);\n",
       "    }, 0);\n",
       "  })()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the environment and reward map to initial state\n",
    "env.reset()\n",
    "env.reset_reward_map()\n",
    "\n",
    "# Create the animation using the best path\n",
    "animation = FuncAnimation(fig, lambda frame: update(frame, (best_path_agent1, best_path_agent2), env, ax), frames=max(len(best_path_agent1), len(best_path_agent2)), interval=100)\n",
    "# Display the animation in Jupyter Notebook\n",
    "HTML(animation.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_best_path(env, best_path):\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     plt.imshow(env.reward_map, cmap='viridis', origin='lower')\n",
    "\n",
    "#     # Plot the path\n",
    "#     for state in best_path:\n",
    "#         plt.scatter(state[1], state[0], c='red', marker='o')\n",
    "\n",
    "#     plt.title(\"Best Path in Grid\")\n",
    "#     plt.show()\n",
    "# plot_best_path(env, best_path)\n",
    "# print(best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Tec\\multi_agentes\\multiagentes-TC2008B\\Q-learning_13_2agents.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m transformed_path\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m iteration \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIteration \u001b[39m\u001b[39m{\u001b[39;00miteration\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mtransform_path(best_path,\u001b[39m \u001b[39;49miteration)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\Tec\\multi_agentes\\multiagentes-TC2008B\\Q-learning_13_2agents.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Add the last point of the iteration\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m iteration \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     transformed_path\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49marray([ROWS \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, transformed_path[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Tec/multi_agentes/multiagentes-TC2008B/Q-learning_13_2agents.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     transformed_path\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, transformed_path[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def transform_path(original_path, iteration):\n",
    "    transformed_path = []\n",
    "    ROWS = 10  # Assuming the number of rows is constant at 10\n",
    "\n",
    "    for x, y in original_path:\n",
    "        if iteration % 2 == 1:\n",
    "            # For odd iterations, increase x and increment y\n",
    "            new_x = x\n",
    "            new_y = y + (iteration - 1)\n",
    "        else:\n",
    "            # For even iterations, decrease x and increment y\n",
    "            new_x = ROWS - 1 - x\n",
    "            new_y = y + (iteration - 1)\n",
    "        \n",
    "        transformed_path.append(np.array([new_x, new_y]))\n",
    "\n",
    "    # Add the last point of the iteration\n",
    "    if iteration % 2 == 1:\n",
    "        transformed_path.append(np.array([ROWS - 1, transformed_path[-1][1] + 1]))\n",
    "    else:\n",
    "        transformed_path.append(np.array([0, transformed_path[-1][1] + 1]))\n",
    "\n",
    "    return transformed_path\n",
    "\n",
    "for iteration in range(1, 4):\n",
    "    print(f\"Iteration {iteration}: {transform_path(best_path, iteration)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_q_values(agent):\n",
    "#     fig, axs = plt.subplots(agent.env.grid_size, agent.env.grid_size, figsize=(20, 20))\n",
    "\n",
    "#     # Iterate over all grid cells\n",
    "#     for i in range(agent.env.grid_size):\n",
    "#         for j in range(agent.env.grid_size):\n",
    "#             ax = axs[i, j]\n",
    "#             q_values = agent.q_table[i, j]\n",
    "\n",
    "#             # Use a bar chart or similar to represent Q-values for each action\n",
    "#             ax.bar(range(len(q_values)), q_values, color=['blue', 'green', 'red', 'purple'])\n",
    "#             ax.set_ylim([-100, 100])  # Assuming Q-values are in this range; adjust as needed\n",
    "#             ax.set_xticks(range(len(q_values)))\n",
    "#             ax.set_xticklabels(['Up', 'Down', 'Left', 'Right'])\n",
    "#             ax.set_title(f\"State ({i}, {j})\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Assuming your agent is named 'agent' and has been trained\n",
    "# plot_q_values(agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
